Vynel
Private by default. Local by design.
Vynel is a fully client-side AI chat application that runs entirely in your browser using WebGPU acceleration. All inference happens locally on your machine â€” there is no backend server and no cloud-based AI.
âš ï¸ Current scope: Vynel is intentionally GPU-only for now. CPU / WASM fallback has been removed to keep the architecture clean and correct.
________________________________________
âœ¨ Features
â€¢	ğŸ”’ 100% local inference (no backend, no API keys)
â€¢	âš¡ WebGPU acceleration (MLC / WebLLM)
â€¢	ğŸ§  Multiple large language models
â€¢	ğŸ’¬ Streaming responses (ChatGPT-style UX)
â€¢	ğŸ”„ Model selector with persistence
â€¢	ğŸ—‚ï¸ Sliding context window
â€¢	ğŸ–¤ Dark UI (black & orange theme)
________________________________________
ğŸ§  Supported Models (WebGPU only)
These models are compiled with MLC and require WebGPU:
â€¢	TinyLlama 1.1B â€” Fast
â€¢	Llama 3 8B â€” Smart
â€¢	Mistral 7B â€” Deep
â€¢	Gemma 2 2B â€” Balanced
All models run locally on your GPU. No model runs on CPU at this stage.
________________________________________
ğŸ“‹ System Requirements
âœ… Operating System
â€¢	Windows 10 / 11 only
macOS and Linux are not supported yet.
________________________________________
âœ… Browser
â€¢	Google Chrome (required)
Chromium-based browsers may work, but Chrome is the only supported browser.
________________________________________
âœ… Hardware
â€¢	A GPU with WebGPU support
â€¢	Modern integrated or discrete GPU (Intel / AMD / NVIDIA)
________________________________________
ğŸ§ª Chrome Setup (VERY IMPORTANT)
WebGPU must be fully enabled in Chrome.
Step 1: Enable WebGPU
1.	Open Chrome
2.	Go to:
3.	chrome://flags
4.	Enable the following flags:
o	WebGPU
o	Unsafe WebGPU Support (if available)
5.	Relaunch Chrome
________________________________________
Step 2: Ensure Hardware Acceleration is ON
1.	Open Chrome Settings
2.	Go to System
3.	Enable:
o	âœ… Use hardware acceleration when available
4.	Relaunch Chrome
________________________________________
Step 3: Verify WebGPU (Optional)
Open DevTools â†’ Console and run:
navigator.gpu
If it returns an object, WebGPU is enabled.
________________________________________
ğŸ› ï¸ Installation (from scratch)
These steps assume nothing is installed on the system.
________________________________________
Step 1: Install Node.js
Download and install Node.js 20+:
ğŸ‘‰ https://nodejs.org/
Verify installation:
node -v
npm -v
________________________________________
Step 2: Clone the repository
git clone https://github.com/<your-username>/vynel.git
cd vynel
________________________________________
Step 3: Install dependencies
npm install
This installs:
â€¢	React
â€¢	Vite
â€¢	@mlc-ai/web-llm
â€¢	react-markdown
â€¢	remark-gfm
________________________________________
Step 4: Start the development server
npm run dev
You should see:
Local: http://localhost:5173/
Open the URL in Google Chrome.
________________________________________
ğŸš€ Usage
1.	Open Vynel in Chrome
2.	Select a model from the dropdown
3.	Start chatting
4.	Responses stream in real time
5.	Use Stop to interrupt generation
6.	Use Clear chat to reset context
If WebGPU is not available, the app will fail to load models.
________________________________________
ğŸ“ Project Structure
src/
â”œâ”€ components/
â”‚  â”œâ”€ ChatApp.jsx      # Main UI + logic
â”‚  â”œâ”€ ChatInput.jsx   # Input + send/stop
â”‚  â””â”€ Header.jsx      # App header
â”‚
â”œâ”€ inference/
â”‚  â”œâ”€ index.js        # WebGPU inference manager
â”‚  â””â”€ webllm.js       # WebLLM / MLC engine
â”‚
â”œâ”€ main.jsx
â”œâ”€ App.jsx
________________________________________
ğŸ” Privacy
â€¢	No backend
â€¢	No cloud inference
â€¢	No API keys
â€¢	No telemetry
â€¢	Model files are downloaded locally
Everything runs entirely on your machine.
________________________________________
ğŸ§­ Roadmap
â€¢	Settings panel (temperature, system prompt)
â€¢	Engine diagnostics panel
â€¢	Better WebGPU capability checks
â€¢	Model download size warnings
â€¢	Mobile WebGPU (when supported)
________________________________________
ğŸ“„ License
MIT License
________________________________________
â­ Final note
Vynel exists to prove that serious, private, local AI in the browser is already possible.
If you like this project, consider starring the repo â­

